# gRPC Server Standardization Strategy

**Version:** 1.0.0 | **Date:** 2025-12-05

MySingle Quant ÌîåÎû´ÌèºÏùò ÎßàÏù¥ÌÅ¨Î°úÏÑúÎπÑÏä§ Í∞Ñ gRPC ÌÜµÏã† ÌëúÏ§ÄÌôî Î∞è ÏÑ±Îä• Í∞úÏÑ† Ï†ÑÎûµ Î¨∏ÏÑúÏûÖÎãàÎã§.

---

## üìã Î™©Ï∞®

1. [ÌòÑÌô© Î∂ÑÏÑù](#1-ÌòÑÌô©-Î∂ÑÏÑù)
2. [Î¨∏Ï†úÏ†ê Î∞è Í∞úÏÑ† Ìè¨Ïù∏Ìä∏](#2-Î¨∏Ï†úÏ†ê-Î∞è-Í∞úÏÑ†-Ìè¨Ïù∏Ìä∏)
3. [BaseGrpcServer ÌëúÏ§ÄÌôî Ï†ÑÎûµ](#3-basegrpcserver-ÌëúÏ§ÄÌôî-Ï†ÑÎûµ)
4. [ÏÑ±Îä• Í∞ïÌôî Î∞©Ïïà](#4-ÏÑ±Îä•-Í∞ïÌôî-Î∞©Ïïà)
5. [ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Í≥ÑÌöç](#5-ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò-Í≥ÑÌöç)
6. [Íµ¨ÌòÑ ÏòàÏãú](#6-Íµ¨ÌòÑ-ÏòàÏãú)

---

## 1. ÌòÑÌô© Î∂ÑÏÑù

### 1.1 ÏÑúÎπÑÏä§Î≥Ñ gRPC ÏÑúÎ≤Ñ Íµ¨ÌòÑ ÌòÑÌô©

| ÏÑúÎπÑÏä§           | ÌååÏùº                     | Interceptor Íµ¨ÏÑ±                                                 | Servicer Ìå®ÌÑ¥                 | ÌäπÏù¥ÏÇ¨Ìï≠                                          |
| ---------------- | ------------------------ | ---------------------------------------------------------------- | ----------------------------- | ------------------------------------------------- |
| **GenAI**        | `server_genai.py`        | 6Í∞ú (Auth, RateLimit, Metadata, Metrics, Logging, ErrorHandling) | Îã®Ïùº ÌÅ¥ÎûòÏä§ + Îã§Ï§ë servicer   | Í∞ÄÏû• ÏôÑÏÑ±ÎèÑ ÎÜíÏùå, Ïª§Ïä§ÌÖÄ interceptor ÏÇ¨Ïö©         |
| **Strategy**     | `server_strategy.py`     | 3Í∞ú (Auth, Metadata, Logging)                                    | Îã®Ïùº ÌÅ¥ÎûòÏä§                   | Helper Ìï®Ïàò Ìå®ÌÑ¥ (`_convert_version_to_protobuf`) |
| **Market Data**  | `server_market_data.py`  | 4Í∞ú (Metrics, Auth, Metadata, Logging)                           | **Mixin Ìå®ÌÑ¥** (9Í∞ú mixin)    | DuckDB Ï∫êÏãú Î†àÏù¥Ïñ¥, ÎèÑÎ©îÏù∏Î≥Ñ Î∂ÑÎ¶¨                 |
| **ML**           | `server_ml.py`           | 3Í∞ú (Auth, Metadata, Logging)                                    | Îã®Ïùº ÌÅ¥ÎûòÏä§                   | Streaming RPC, Redis ÏùºÏùº Ïπ¥Ïö¥ÌÑ∞                  |
| **Indicator**    | `server_indicator.py`    | 3Í∞ú (Auth, Metadata, Logging)                                    | Îã®Ïùº ÌÅ¥ÎûòÏä§                   | Static service Î©îÏÑúÎìú ÏÇ¨Ïö©                        |
| **Subscription** | `server_subscription.py` | ÏóÜÏùå                                                             | Wrapper ÌÅ¥ÎûòÏä§ (`GrpcServer`) | ÎØ∏ÏôÑÏÑ± (proto ÎØ∏Îì±Î°ù)                             |

### 1.2 Interceptor ÏÇ¨Ïö© ÌòÑÌô©

#### mysingle.grpc Ìå®ÌÇ§ÏßÄ Ï†úÍ≥µ (Í≥µÌÜµ)
- ‚úÖ `AuthInterceptor` - user_id Í≤ÄÏ¶ù
- ‚úÖ `LoggingInterceptor` - Íµ¨Ï°∞ÌôîÎêú Î°úÍπÖ
- ‚úÖ `MetadataInterceptor` - correlation_id ÏûêÎèô ÏÉùÏÑ±
- ‚úÖ `ClientAuthInterceptor` - ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï£ºÏûÖ

#### ÏÑúÎπÑÏä§Î≥Ñ Ïª§Ïä§ÌÖÄ Interceptor
- **GenAI**: `ErrorHandlingInterceptor`, `MetricsInterceptor`, `RateLimiterInterceptor`
- **Market Data**: `MetricsInterceptor` (Î≥ÑÎèÑ Íµ¨ÌòÑ)
- **Í∏∞ÌÉÄ ÏÑúÎπÑÏä§**: mysingle.grpcÎßå ÏÇ¨Ïö©

### 1.3 ÏÑúÎ≤Ñ Ï¥àÍ∏∞Ìôî Ìå®ÌÑ¥ ÎπÑÍµê

```python
# Pattern A: Ìï®Ïàò Í∏∞Î∞ò (GenAI, Market Data)
def create_grpc_server() -> grpc.aio.Server:
    server = grpc.aio.server(...)
    # servicer Îì±Î°ù
    return server

async def serve_grpc_with_shutdown(port):
    server = create_grpc_server()
    await server.start()
    await server.wait_for_termination()

# Pattern B: ÌÅ¥ÎûòÏä§ Í∏∞Î∞ò (Subscription)
class GrpcServer:
    def __init__(self, port, max_workers):
        ...
    async def start(self):
        ...
    async def stop(self, grace_period):
        ...

# Pattern C: Îã®Ïàú Ìï®Ïàò (Strategy, ML, Indicator)
async def start_grpc_server(port):
    server = grpc.aio.server(...)
    # servicer Îì±Î°ù
    await server.start()
    return server
```

---

## 2. Î¨∏Ï†úÏ†ê Î∞è Í∞úÏÑ† Ìè¨Ïù∏Ìä∏

### üî¥ Critical Issues

#### 2.1 ÏùºÍ¥ÄÏÑ± Î∂ÄÏû¨
- **ÏÑúÎ°ú Îã§Î•∏ Ï¥àÍ∏∞Ìôî Ìå®ÌÑ¥**: 3Í∞ÄÏßÄ Ìå®ÌÑ¥ ÌòºÏû¨ (Ìï®Ïàò, ÌÅ¥ÎûòÏä§, ÌïòÏù¥Î∏åÎ¶¨Îìú)
- **Interceptor ÏàúÏÑú Î∂àÏùºÏπò**:
  - GenAI: Auth ‚Üí RateLimit ‚Üí Metadata ‚Üí Metrics ‚Üí Logging ‚Üí Error
  - Market Data: Metrics ‚Üí Auth ‚Üí Metadata ‚Üí Logging
  - Îã§Î•∏ ÏÑúÎπÑÏä§: Auth ‚Üí Metadata ‚Üí Logging
- **ÎÑ§Ïù¥Î∞ç Î∂àÏùºÏπò**:
  - `create_grpc_server()` vs `start_grpc_server()` vs `serve_grpc_with_shutdown()`
  - `MLServiceServicer` vs `StrategyServiceServicer` (Ï§ëÎ≥µ "Service")

#### 2.2 Ï§ëÎ≥µ ÏΩîÎìú
- **Interceptor Ï§ëÎ≥µ Íµ¨ÌòÑ**: GenAIÏôÄ Market DataÍ∞Ä Í∞ÅÍ∞Å `MetricsInterceptor` Íµ¨ÌòÑ
- **ÏÑúÎ≤Ñ ÏòµÏÖò Ï§ëÎ≥µ Ï†ïÏùò**: keepalive, max_workers Îì± Îß§ ÏÑúÎπÑÏä§ÎßàÎã§ Ïû¨Ï†ïÏùò
- **Reflection ÌôúÏÑ±Ìôî ÏΩîÎìú Ï§ëÎ≥µ**: SERVICE_NAMES Ï†ïÏùò Î∞è enable Î°úÏßÅ Î∞òÎ≥µ

#### 2.3 Ïú†ÏßÄÎ≥¥ÏàòÏÑ±
- **ÏÑ§Ï†ï ÌïòÎìúÏΩîÎî©**:
  ```python
  # GenAI
  ("grpc.keepalive_time_ms", settings.GRPC_KEEPALIVE_TIME_MS)

  # Market Data
  ("grpc.keepalive_time_ms", 30000)  # ÌïòÎìúÏΩîÎî©
  ```
- **ÏóêÎü¨ Ï≤òÎ¶¨ Î∂àÏùºÏπò**: GenAIÎßå `ErrorHandlingInterceptor` ÏÇ¨Ïö©
- **Graceful Shutdown ÎàÑÎùΩ**: SubscriptionÎßå Íµ¨ÌòÑ, ÎÇòÎ®∏ÏßÄÎäî ÎàÑÎùΩ

#### 2.4 ÏÑ±Îä• Ïù¥Ïäà
- **Ï∫êÏãú Ï†ÑÎûµ Î∂àÏùºÏπò**:
  - Market Data: DuckDB Ï∫êÏãú Î†àÏù¥Ïñ¥
  - ML: Redis ÏùºÏùº Ïπ¥Ïö¥ÌÑ∞
  - ÎÇòÎ®∏ÏßÄ: Ï∫êÏãú ÏóÜÏùå
- **Connection Pooling Î∂ÄÏû¨**: MongoDB, Redis Ïó∞Í≤∞Ïù¥ servicerÎßàÎã§ ÏÉùÏÑ±Îê† Í∞ÄÎä•ÏÑ±
- **Î©îÌä∏Î¶≠ ÏàòÏßë ÎàÑÎùΩ**: GenAI, Market DataÎßå Î©îÌä∏Î¶≠ ÏàòÏßë

### üü° Improvement Points

#### 2.5 ÌôïÏû•ÏÑ±
- **Interceptor Ï∂îÍ∞Ä Ïãú Î™®Îì† ÏÑúÎπÑÏä§ ÏàòÏ†ï ÌïÑÏöî**
- **Í≥µÌÜµ Î°úÏßÅ Ïû¨ÏÇ¨Ïö© Î∂àÍ∞Ä**: Health check, metadata Ï∂îÏ∂ú Îì±
- **ÌÖåÏä§Ìä∏ Ïñ¥Î†§ÏõÄ**: Í∞Å ÏÑúÎπÑÏä§ÎßàÎã§ Îã§Î•∏ Mock Ï†ÑÎûµ ÌïÑÏöî

#### 2.6 Î™®ÎãàÌÑ∞ÎßÅ
- **ÌÜµÏùºÎêú Î©îÌä∏Î¶≠ Î∂ÄÏû¨**:
  - Latency, request count Îì± ÌëúÏ§Ä Î©îÌä∏Î¶≠ ÎàÑÎùΩ
  - Prometheus exporter ÎØ∏Íµ¨ÌòÑ
- **Î°úÍπÖ Ìè¨Îß∑ Î∂àÏùºÏπò**:
  - GenAI: "gRPC call started"
  - Í∏∞ÌÉÄ: Î°úÍ∑∏ ÏóÜÏùå (mysingle.grpc.LoggingInterceptorÎßå ÏÇ¨Ïö©)

---

## 3. BaseGrpcServer ÌëúÏ§ÄÌôî Ï†ÑÎûµ

### 3.1 ÏÑ§Í≥Ñ ÏõêÏπô

1. **Convention over Configuration**: Í∏∞Î≥∏ ÏÑ§Ï†ïÏúºÎ°ú 80% Ïª§Î≤Ñ
2. **Extensibility**: Hook Î©îÏÑúÎìúÎ°ú Ïª§Ïä§ÌÑ∞ÎßàÏù¥Ïßï ÏßÄÏõê
3. **Type Safety**: Pydantic Í∏∞Î∞ò ÏÑ§Ï†ï Ïä§ÌÇ§Îßà
4. **Observability**: Î©îÌä∏Î¶≠, Î°úÍπÖ, Ìä∏Î†àÏù¥Ïã± Í∏∞Î≥∏ Ï†úÍ≥µ
5. **Testability**: Mock-friendly Ïù∏ÌÑ∞ÌéòÏù¥Ïä§
6. **CommonSettings ÌÜµÌï©**: ÌôòÍ≤ΩÎ≥ÄÏàò Í∏∞Î∞ò Ï§ëÏïôÌôîÎêú ÏÑ§Ï†ï Í¥ÄÎ¶¨

### 3.2 CommonSettings ÌÜµÌï© Ï†ÑÎûµ

**Î™®Îì† ÎßàÏù¥ÌÅ¨Î°úÏÑúÎπÑÏä§Îäî `mysingle.core.config.CommonSettings`Î•º ÏÉÅÏÜçÌïòÏó¨ ÏÑúÎπÑÏä§Î≥Ñ ÏÑ§Ï†ïÏùÑ Íµ¨ÏÑ±Ìï©ÎãàÎã§.**

#### 3.2.1 CommonSettingsÏóê Ï∂îÍ∞ÄÎêú gRPC ÏÑ§Ï†ï

```python
# mysingle/core/config.py

class CommonSettings(BaseSettings):
    # ... Í∏∞Ï°¥ ÏÑ§Ï†ï ...

    # REDIS DB ALLOCATION
    REDIS_DB_USER: int = 0  # User authentication cache
    REDIS_DB_MARKET: int = 1  # Market data cache
    REDIS_DB_GRPC: int = 2  # gRPC response cache
    REDIS_DB_RATE_LIMIT: int = 3  # Rate limiting counters
    REDIS_DB_SESSION: int = 4  # Session storage

    # GRPC SERVER SETTINGS
    GRPC_SERVER_PORT: int = 50051  # Default gRPC port (override per service)
    GRPC_SERVER_MAX_WORKERS: int = 10  # Thread pool size
    GRPC_SERVER_ENABLE_REFLECTION: bool = False  # Enable in development only

    # GRPC Interceptor Settings
    GRPC_ENABLE_AUTH: bool = True  # Require user_id metadata
    GRPC_ENABLE_RATE_LIMITING: bool = True  # Enable rate limiting
    GRPC_ENABLE_METRICS: bool = True  # Prometheus metrics collection
    GRPC_ENABLE_ERROR_HANDLING: bool = True  # Auto error conversion

    # GRPC Rate Limiting
    GRPC_RATE_LIMIT_MAX_REQUESTS: int = 1000  # Max requests per window
    GRPC_RATE_LIMIT_WINDOW_SECONDS: int = 60  # Rate limit window (seconds)

    # GRPC Server Options
    GRPC_KEEPALIVE_TIME_MS: int = 30000  # TCP keepalive time (30s)
    GRPC_KEEPALIVE_TIMEOUT_MS: int = 10000  # TCP keepalive timeout (10s)
    GRPC_MAX_CONCURRENT_STREAMS: int = 100  # Max concurrent streams
    GRPC_MAX_MESSAGE_LENGTH: int = 10 * 1024 * 1024  # Max message size (10MB)

    # GRPC Cache Settings
    GRPC_CACHE_ENABLED: bool = True  # Enable response caching
    GRPC_CACHE_L1_TTL_SECONDS: int = 300  # L1 in-memory TTL (5 min)
    GRPC_CACHE_L1_MAX_SIZE: int = 100  # L1 LRU cache size
    GRPC_CACHE_L2_TTL_SECONDS: int = 3600  # L2 Redis TTL (1 hour)
    GRPC_CACHE_DEFAULT_TTL: int = 300  # Default cache TTL (5 min)
```

#### 3.2.2 ÏÑúÎπÑÏä§Î≥Ñ ÏÑ§Ï†ï ÏòàÏãú

```python
# strategy-service/app/core/config.py

from mysingle.core.config import CommonSettings

class StrategyServiceSettings(CommonSettings):
    \"\"\"Strategy Service Ï†ÑÏö© ÏÑ§Ï†ï\"\"\"

    # ÏÑúÎπÑÏä§ Í≥†Ïú† ÏÑ§Ï†ï
    SERVICE_NAME: str = "strategy-service"
    STRATEGY_GRPC_PORT: int = 50051  # gRPC Ìè¨Ìä∏ Ïò§Î≤ÑÎùºÏù¥Îìú

    # gRPC ÏÑ§Ï†ï Ïò§Î≤ÑÎùºÏù¥Îìú (ÌïÑÏöîÏãú)
    GRPC_RATE_LIMIT_MAX_REQUESTS: int = 2000  # StrategyÎäî Îçî ÎÜíÏùÄ ÌïúÎèÑ

# ÏÑúÎπÑÏä§ ÏÑ§Ï†ï Ïù∏Ïä§ÌÑ¥Ïä§
settings = StrategyServiceSettings()
```

#### 3.2.3 ÌôòÍ≤ΩÎ≥ÄÏàò ÌååÏùº (.env)

```bash
# .env (ÌîÑÎ°úÎçïÏÖò)

# Service Config
SERVICE_NAME=strategy-service
ENVIRONMENT=production

# gRPC Server
GRPC_SERVER_PORT=50051
GRPC_SERVER_MAX_WORKERS=20  # ÌîÑÎ°úÎçïÏÖòÏóêÏÑú Ï¶ùÍ∞Ä
GRPC_SERVER_ENABLE_REFLECTION=false  # ÌîÑÎ°úÎçïÏÖòÏóêÏÑú ÎπÑÌôúÏÑ±Ìôî

# gRPC Interceptors
GRPC_ENABLE_AUTH=true
GRPC_ENABLE_RATE_LIMITING=true
GRPC_ENABLE_METRICS=true

# gRPC Rate Limiting
GRPC_RATE_LIMIT_MAX_REQUESTS=2000
GRPC_RATE_LIMIT_WINDOW_SECONDS=60

# gRPC Cache
GRPC_CACHE_ENABLED=true
GRPC_CACHE_L1_TTL_SECONDS=300
GRPC_CACHE_L1_MAX_SIZE=200  # ÌîÑÎ°úÎçïÏÖòÏóêÏÑú Ï¶ùÍ∞Ä
GRPC_CACHE_L2_TTL_SECONDS=3600

# Redis DB Allocation
REDIS_DB_GRPC=2
REDIS_DB_RATE_LIMIT=3
```

### 3.3 ÏïÑÌÇ§ÌÖçÏ≤ò Îã§Ïù¥Ïñ¥Í∑∏Îû®

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   FastAPI Application                    ‚îÇ
‚îÇ                   (HTTP Gateway)                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              BaseGrpcServer (Abstract)                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Configuration (Pydantic Model)                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - port, max_workers, interceptors, options       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Lifecycle Hooks                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - before_start(), after_start()                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - before_stop(), after_stop()                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - register_servicers() (abstract)                ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Default Interceptor Chain                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  1. MetricsInterceptor (ÏÑ±Îä• Ï∏°Ï†ï)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  2. AuthInterceptor (user_id Í≤ÄÏ¶ù)               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  3. RateLimiterInterceptor (ÏöîÏ≤≠ Ï†úÌïú)           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  4. MetadataInterceptor (correlation_id)          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  5. LoggingInterceptor (Íµ¨Ï°∞Ìôî Î°úÍπÖ)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  6. ErrorHandlingInterceptor (ÏóêÎü¨ Î≥ÄÌôò)         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Resource Management                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Service Factory integration                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Redis/MongoDB connection pooling               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Graceful shutdown                              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº            ‚ñº            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ GenAIServer  ‚îÇ MLServer ‚îÇ StrategyServer ‚îÇ
‚îÇ (extends     ‚îÇ(extends  ‚îÇ(extends        ‚îÇ
‚îÇ  Base)       ‚îÇ Base)    ‚îÇ Base)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.3 ÌïµÏã¨ ÌÅ¥ÎûòÏä§ Íµ¨Ï°∞

```python
# mysingle/grpc/server.py

from abc import ABC, abstractmethod
from typing import Any, Callable

import grpc
from pydantic import BaseModel, Field

from mysingle.core import get_structured_logger
from mysingle.grpc import (
    AuthInterceptor,
    ErrorHandlingInterceptor,
    LoggingInterceptor,
    MetadataInterceptor,
    MetricsInterceptor,
    RateLimiterInterceptor,
)

logger = get_structured_logger(__name__)


class GrpcServerConfig(BaseModel):
    """gRPC ÏÑúÎ≤Ñ ÏÑ§Ï†ï Ïä§ÌÇ§Îßà"""

    # Basic settings
    service_name: str = Field(..., description="ÏÑúÎπÑÏä§ Ïù¥Î¶Ñ (Ïòà: genai-service)")
    port: int = Field(..., description="gRPC ÏÑúÎ≤Ñ Ìè¨Ìä∏")
    max_workers: int = Field(default=10, description="Thread pool ÌÅ¨Í∏∞")

    # Interceptor settings
    enable_auth: bool = Field(default=True, description="Ïù∏Ï¶ù ÌôúÏÑ±Ìôî")
    enable_rate_limiting: bool = Field(default=True, description="Rate limiting ÌôúÏÑ±Ìôî")
    enable_metrics: bool = Field(default=True, description="Î©îÌä∏Î¶≠ ÏàòÏßë ÌôúÏÑ±Ìôî")
    enable_error_handling: bool = Field(default=True, description="ÏóêÎü¨ Ìï∏Îì§ÎßÅ ÌôúÏÑ±Ìôî")

    # Rate limiting
    rate_limit_max_requests: int = Field(default=1000, description="Rate limit ÏµúÎåÄ ÏöîÏ≤≠ Ïàò")
    rate_limit_window_seconds: int = Field(default=60, description="Rate limit ÏúàÎèÑÏö∞ (Ï¥à)")

    # gRPC options
    keepalive_time_ms: int = Field(default=30000, description="Keepalive time (ms)")
    keepalive_timeout_ms: int = Field(default=10000, description="Keepalive timeout (ms)")
    max_concurrent_streams: int = Field(default=100, description="ÏµúÎåÄ ÎèôÏãú Ïä§Ìä∏Î¶º")
    max_message_length: int = Field(default=10 * 1024 * 1024, description="ÏµúÎåÄ Î©îÏãúÏßÄ ÌÅ¨Í∏∞ (10MB)")

    # Reflection (Í∞úÎ∞ú ÌôòÍ≤Ω)
    enable_reflection: bool = Field(default=False, description="gRPC reflection ÌôúÏÑ±Ìôî (grpcurl)")
    reflection_service_names: list[str] = Field(default_factory=list, description="Reflection ÏÑúÎπÑÏä§ Ïù¥Î¶Ñ")

    # Exempt methods (Ïù∏Ï¶ù Î©¥Ï†ú)
    auth_exempt_methods: list[str] = Field(default_factory=list, description="Ïù∏Ï¶ù Î©¥Ï†ú Î©îÏÑúÎìú")

    class Config:
        use_enum_values = True


class BaseGrpcServer(ABC):
    """
    gRPC ÏÑúÎ≤Ñ Í∏∞Î≥∏ ÌÅ¥ÎûòÏä§.

    Î™®Îì† ÎßàÏù¥ÌÅ¨Î°úÏÑúÎπÑÏä§Ïùò gRPC ÏÑúÎ≤ÑÎäî Ïù¥ ÌÅ¥ÎûòÏä§Î•º ÏÉÅÏÜçÎ∞õÏïÑ Íµ¨ÌòÑÌï©ÎãàÎã§.

    Example:
        ```python
        from app.core.config import settings
        from mysingle.grpc.server import BaseGrpcServer, GrpcServerConfig

        class GenAIServer(BaseGrpcServer):
            def register_servicers(self, server: grpc.aio.Server):
                from app.servicers import ChatOpsServicer
                from mysingle.protos.services.genai.v1 import chatops_pb2_grpc

                chatops_pb2_grpc.add_ChatOpsServiceServicer_to_server(
                    ChatOpsServicer(self.service_factory), server
                )

        # CommonSettingsÏóêÏÑú ÏûêÎèôÏúºÎ°ú ÏÑ§Ï†ï Î°úÎìú
        config = GrpcServerConfig.from_settings(
            settings,
            service_name="genai-service",
        )
        server = GenAIServer(config)
        await server.start()
        ```
    """

    def __init__(self, config: GrpcServerConfig):
        """
        Args:
            config: gRPC ÏÑúÎ≤Ñ ÏÑ§Ï†ï
        """
        self.config = config
        self.server: grpc.aio.Server | None = None
        self.service_factory: Any | None = None  # ÏÑúÎπÑÏä§Î≥ÑÎ°ú Ï£ºÏûÖ

        logger.info(
            "BaseGrpcServer initialized",
            service=config.service_name,
            port=config.port,
        )

    def _build_interceptors(self) -> list[grpc.aio.ServerInterceptor]:
        """Interceptor Ï≤¥Ïù∏ Íµ¨ÏÑ± (ÏàúÏÑú Ï§ëÏöî)"""
        interceptors = []

        # 1. Metrics (Í∞ÄÏû• Î®ºÏ†Ä - Ï†ÑÏ≤¥ latency Ï∏°Ï†ï)
        if self.config.enable_metrics:
            interceptors.append(MetricsInterceptor(service_name=self.config.service_name))

        # 2. Auth (Ïù∏Ï¶ù Ïã§Ìå® Ïãú Ï°∞Í∏∞ Ï¢ÖÎ£å)
        if self.config.enable_auth:
            interceptors.append(
                AuthInterceptor(
                    require_auth=True,
                    exempt_methods=self.config.auth_exempt_methods,
                )
            )

        # 3. Rate Limiting (Ïù∏Ï¶ù ÌõÑ Ï¶âÏãú)
        if self.config.enable_rate_limiting:
            interceptors.append(
                RateLimiterInterceptor(
                    max_requests=self.config.rate_limit_max_requests,
                    window_seconds=self.config.rate_limit_window_seconds,
                )
            )

        # 4. Metadata (correlation_id ÏÉùÏÑ±)
        interceptors.append(MetadataInterceptor(auto_generate=True))

        # 5. Logging (Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ïù¥ÌõÑ)
        interceptors.append(LoggingInterceptor())

        # 6. Error Handling (Í∞ÄÏû• ÎßàÏßÄÎßâ - Î™®Îì† ÏóêÎü¨ Ï∫êÏπò)
        if self.config.enable_error_handling:
            interceptors.append(ErrorHandlingInterceptor())

        logger.info(
            "Interceptor chain built",
            service=self.config.service_name,
            count=len(interceptors),
        )
        return interceptors

    def _build_server_options(self) -> list[tuple[str, Any]]:
        """gRPC ÏÑúÎ≤Ñ ÏòµÏÖò Íµ¨ÏÑ±"""
        return [
            ("grpc.max_concurrent_streams", self.config.max_concurrent_streams),
            ("grpc.max_receive_message_length", self.config.max_message_length),
            ("grpc.max_send_message_length", self.config.max_message_length),
            ("grpc.keepalive_time_ms", self.config.keepalive_time_ms),
            ("grpc.keepalive_timeout_ms", self.config.keepalive_timeout_ms),
            ("grpc.http2.max_pings_without_data", 0),
            ("grpc.keepalive_permit_without_calls", 1),
        ]

    @abstractmethod
    def register_servicers(self, server: grpc.aio.Server) -> None:
        """
        ServicerÎ•º ÏÑúÎ≤ÑÏóê Îì±Î°ù (Í∞Å ÏÑúÎπÑÏä§ÏóêÏÑú Íµ¨ÌòÑ ÌïÑÏàò).

        Args:
            server: gRPC ÏÑúÎ≤Ñ Ïù∏Ïä§ÌÑ¥Ïä§

        Example:
            ```python
            def register_servicers(self, server):
                from mysingle.protos.services.genai.v1 import chatops_pb2_grpc
                chatops_pb2_grpc.add_ChatOpsServiceServicer_to_server(
                    ChatOpsServicer(), server
                )
            ```
        """
        raise NotImplementedError("Subclass must implement register_servicers()")

    async def before_start(self) -> None:
        """ÏÑúÎ≤Ñ ÏãúÏûë Ï†Ñ Hook (ÏÑ†ÌÉùÏ†Å Ïò§Î≤ÑÎùºÏù¥Îìú)"""
        pass

    async def after_start(self) -> None:
        """ÏÑúÎ≤Ñ ÏãúÏûë ÌõÑ Hook (ÏÑ†ÌÉùÏ†Å Ïò§Î≤ÑÎùºÏù¥Îìú)"""
        pass

    async def before_stop(self) -> None:
        """ÏÑúÎ≤Ñ Ï§ëÏßÄ Ï†Ñ Hook (ÏÑ†ÌÉùÏ†Å Ïò§Î≤ÑÎùºÏù¥Îìú)"""
        pass

    async def after_stop(self) -> None:
        """ÏÑúÎ≤Ñ Ï§ëÏßÄ ÌõÑ Hook (ÏÑ†ÌÉùÏ†Å Ïò§Î≤ÑÎùºÏù¥Îìú)"""
        pass

    def create_server(self) -> grpc.aio.Server:
        """gRPC ÏÑúÎ≤Ñ Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±"""
        from concurrent import futures

        interceptors = self._build_interceptors()
        options = self._build_server_options()

        server = grpc.aio.server(
            futures.ThreadPoolExecutor(max_workers=self.config.max_workers),
            interceptors=interceptors,
            options=options,
        )

        # Servicer Îì±Î°ù (Í∞Å ÏÑúÎπÑÏä§Î≥Ñ Íµ¨ÌòÑ)
        self.register_servicers(server)

        # gRPC Reflection (Í∞úÎ∞ú ÌôòÍ≤Ω)
        if self.config.enable_reflection:
            from grpc_reflection.v1alpha import reflection

            reflection.enable_server_reflection(
                self.config.reflection_service_names, server
            )
            logger.info(
                "gRPC reflection enabled",
                service=self.config.service_name,
                services=self.config.reflection_service_names,
            )

        # Ìè¨Ìä∏ Î∞îÏù∏Îî©
        server.add_insecure_port(f"[::]:{self.config.port}")

        logger.info(
            "gRPC server created",
            service=self.config.service_name,
            port=self.config.port,
            max_workers=self.config.max_workers,
        )

        return server

    async def start(self) -> None:
        """gRPC ÏÑúÎ≤Ñ ÏãúÏûë"""
        await self.before_start()

        self.server = self.create_server()
        await self.server.start()

        logger.info(
            "üöÄ gRPC server started",
            service=self.config.service_name,
            port=self.config.port,
        )

        await self.after_start()

    async def stop(self, grace_period: float = 5.0) -> None:
        """gRPC ÏÑúÎ≤Ñ Ï§ëÏßÄ (graceful shutdown)"""
        if self.server is None:
            logger.warning("gRPC server not started")
            return

        await self.before_stop()

        logger.info(
            "Stopping gRPC server",
            service=self.config.service_name,
            grace_period=grace_period,
        )

        await self.server.stop(grace_period)

        logger.info("‚úÖ gRPC server stopped", service=self.config.service_name)

        await self.after_stop()

    async def wait_for_termination(self) -> None:
        """ÏÑúÎ≤Ñ Ï¢ÖÎ£å ÎåÄÍ∏∞"""
        if self.server is None:
            logger.warning("gRPC server not started")
            return

        await self.server.wait_for_termination()

    async def serve(self) -> None:
        """ÏÑúÎ≤Ñ ÏãúÏûë Î∞è Ï¢ÖÎ£å ÎåÄÍ∏∞ (Ìé∏Ïùò Î©îÏÑúÎìú)"""
        await self.start()
        await self.wait_for_termination()
```

### 3.4 Ï∂îÍ∞Ä Interceptor Íµ¨ÌòÑ

mysingle.grpc Ìå®ÌÇ§ÏßÄÏóê Îã§Ïùå interceptorÎ•º Ï∂îÍ∞ÄÌï¥Ïïº Ìï©ÎãàÎã§:

```python
# mysingle/grpc/interceptors.py Ïóê Ï∂îÍ∞Ä

class MetricsInterceptor(grpc.aio.ServerInterceptor):
    """
    gRPC Î©îÌä∏Î¶≠ ÏàòÏßë Ïù∏ÌÑ∞ÏÖâÌÑ∞.

    - Latency (P50, P95, P99)
    - Request count (ÏÑ±Í≥µ/Ïã§Ìå®)
    - Error rate
    - Active connections

    Prometheus exporterÏôÄ ÌÜµÌï©.
    """

    def __init__(self, service_name: str):
        self.service_name = service_name
        # Prometheus metrics Ï¥àÍ∏∞Ìôî
        from prometheus_client import Counter, Histogram

        self.request_count = Counter(
            "grpc_requests_total",
            "Total gRPC requests",
            ["service", "method", "status"],
        )
        self.request_latency = Histogram(
            "grpc_request_duration_seconds",
            "gRPC request latency",
            ["service", "method"],
        )

    async def intercept_service(self, continuation, handler_call_details):
        import time

        method = handler_call_details.method
        start = time.time()

        try:
            handler = await continuation(handler_call_details)
            self.request_count.labels(
                service=self.service_name, method=method, status="OK"
            ).inc()
            return handler
        except Exception as e:
            self.request_count.labels(
                service=self.service_name, method=method, status="ERROR"
            ).inc()
            raise
        finally:
            elapsed = time.time() - start
            self.request_latency.labels(service=self.service_name, method=method).observe(
                elapsed
            )


class ErrorHandlingInterceptor(grpc.aio.ServerInterceptor):
    """
    gRPC ÏóêÎü¨ Ìï∏Îì§ÎßÅ Ïù∏ÌÑ∞ÏÖâÌÑ∞.

    Python ÏòàÏô∏Î•º gRPC ÏÉÅÌÉú ÏΩîÎìúÎ°ú Î≥ÄÌôò:
    - ValueError ‚Üí INVALID_ARGUMENT
    - PermissionError ‚Üí PERMISSION_DENIED
    - FileNotFoundError ‚Üí NOT_FOUND
    - Exception ‚Üí INTERNAL
    """

    async def intercept_service(self, continuation, handler_call_details):
        try:
            return await continuation(handler_call_details)
        except grpc.RpcError:
            # gRPC ÏóêÎü¨Îäî Í∑∏ÎåÄÎ°ú Ï†ÑÎã¨
            raise
        except ValueError as e:
            await context.abort(grpc.StatusCode.INVALID_ARGUMENT, str(e))
        except PermissionError as e:
            await context.abort(grpc.StatusCode.PERMISSION_DENIED, str(e))
        except FileNotFoundError as e:
            await context.abort(grpc.StatusCode.NOT_FOUND, str(e))
        except Exception as e:
            logger.error("Unhandled exception in gRPC", error=str(e), exc_info=True)
            await context.abort(grpc.StatusCode.INTERNAL, "Internal server error")


class RateLimiterInterceptor(grpc.aio.ServerInterceptor):
    """
    gRPC Rate Limiting Ïù∏ÌÑ∞ÏÖâÌÑ∞.

    Redis Í∏∞Î∞ò Ïä¨ÎùºÏù¥Îî© ÏúàÎèÑÏö∞ ÏïåÍ≥†Î¶¨Ï¶ò:
    - user_idÎ≥Ñ ÏöîÏ≤≠ Ï†úÌïú
    - Ï†ÑÏó≠ ÏöîÏ≤≠ Ï†úÌïú

    Args:
        max_requests: ÏúàÎèÑÏö∞Îãπ ÏµúÎåÄ ÏöîÏ≤≠ Ïàò
        window_seconds: ÏúàÎèÑÏö∞ ÌÅ¨Í∏∞ (Ï¥à)
    """

    def __init__(self, max_requests: int, window_seconds: int):
        self.max_requests = max_requests
        self.window_seconds = window_seconds

    async def intercept_service(self, continuation, handler_call_details):
        import time

        metadata = dict(handler_call_details.invocation_metadata or [])
        user_id = metadata.get("user-id", "anonymous")

        # RedisÏóêÏÑú ÌòÑÏû¨ ÏöîÏ≤≠ Ïàò ÌôïÏù∏
        from mysingle.database import get_redis_client

        redis = await get_redis_client()
        key = f"rate_limit:{user_id}:{int(time.time() / self.window_seconds)}"

        current_count = await redis.incr(key)
        await redis.expire(key, self.window_seconds)

        if current_count > self.max_requests:
            await context.abort(
                grpc.StatusCode.RESOURCE_EXHAUSTED,
                f"Rate limit exceeded: {self.max_requests}/{self.window_seconds}s",
            )

        return await continuation(handler_call_details)
```

---

## 4. ÏÑ±Îä• Í∞ïÌôî Î∞©Ïïà

### 4.1 Redis Ï∫êÏãú Ï†ÑÎûµ

#### 4.1.1 Îã§Ï∏µ Ï∫êÏãú ÏïÑÌÇ§ÌÖçÏ≤ò

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  gRPC Request                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ L1: In-Memory   ‚îÇ (5Î∂Ñ TTL, LRU 100Í∞ú)
         ‚îÇ Python dict     ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ Miss
                  ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ L2: Redis       ‚îÇ (1ÏãúÍ∞Ñ TTL)
         ‚îÇ String/Hash     ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ Miss
                  ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ L3: DuckDB      ‚îÇ (Market Data only)
         ‚îÇ Parquet cache   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ Miss
                  ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ L4: MongoDB     ‚îÇ
         ‚îÇ Primary DB      ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 4.1.2 Ï∫êÏãú Íµ¨ÌòÑ (BaseRedisCache Í∏∞Î∞ò)

**ÏÑ§Í≥Ñ ÏõêÏπô:**
- ‚úÖ `mysingle.database.BaseRedisCache` ÏÉÅÏÜçÏúºÎ°ú Redis Í∏∞Îä• Ïû¨ÏÇ¨Ïö©
- ‚úÖ Protobuf Î©îÏãúÏßÄ ÏßÅÎ†¨Ìôî ÏßÄÏõê (`.SerializeToString()` / `.ParseFromString()`)
- ‚úÖ L1 In-Memory LRU Ï∫êÏãú Ï∂îÍ∞Ä (Redis Î∂ÄÌïò Í∞êÏÜå)
- ‚úÖ Prometheus Î©îÌä∏Î¶≠ ÏûêÎèô ÏàòÏßë (cache_hits, cache_misses)
- ‚úÖ gRPC Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌÜµÌï© (user_id, correlation_id)

```python
# mysingle/grpc/cache.py

import hashlib
import json
import time
from functools import wraps
from typing import Any, Callable, Optional, TypeVar

from google.protobuf.message import Message as ProtoMessage
from prometheus_client import Counter

from mysingle.core import get_structured_logger
from mysingle.database.redis_cache import BaseRedisCache

logger = get_structured_logger(__name__)

# Î©îÌä∏Î¶≠ Ï†ïÏùò
grpc_cache_hits = Counter(
    "mysingle_grpc_cache_hits_total",
    "gRPC cache hits",
    ["service", "method", "layer"],
)
grpc_cache_misses = Counter(
    "mysingle_grpc_cache_misses_total",
    "gRPC cache misses",
    ["service", "method"],
)

T = TypeVar("T")


class GrpcCache(BaseRedisCache[T]):
    """
    gRPC Ï†ÑÏö© 2-tier Ï∫êÏãú (L1: In-Memory + L2: Redis)

    BaseRedisCacheÎ•º ÏÉÅÏÜçÎ∞õÏïÑ Redis Ïó∞Í≤∞ Í¥ÄÎ¶¨Î•º Ïû¨ÏÇ¨Ïö©ÌïòÍ≥†,
    gRPC ÌäπÌôî Í∏∞Îä•(Protobuf ÏßÅÎ†¨Ìôî, Î©îÌÉÄÎç∞Ïù¥ÌÑ∞)ÏùÑ Ï∂îÍ∞ÄÌï©ÎãàÎã§.

    Example:
        ```python
        # ServicerÏóêÏÑú ÏÇ¨Ïö©
        class StrategyServiceServicer:
            def __init__(self):
                self.cache = GrpcCache(
                    service_name="strategy-service",
                    redis_db=2,  # gRPC Ï†ÑÏö© DB
                )

            @grpc_cached(ttl=300)
            async def GetStrategyVersion(self, request, context):
                # ÏûêÎèô Ï∫êÏã± Ï†ÅÏö©
                ...
        ```
    """

    def __init__(
        self,
        *,
        service_name: str,
        redis_db: int = 2,  # gRPC Ï†ÑÏö© DB (0: user, 1: market, 2: grpc)
        memory_ttl: int = 300,  # L1 TTL (5Î∂Ñ)
        memory_max_size: int = 100,  # L1 LRU ÌÅ¨Í∏∞
    ):
        # BaseRedisCache Ï¥àÍ∏∞Ìôî (key_prefix="grpc:{service_name}")
        super().__init__(
            key_prefix=f"grpc:{service_name}",
            default_ttl=3600,  # L2 Í∏∞Î≥∏ TTL (1ÏãúÍ∞Ñ)
            redis_db=redis_db,
            use_json=False,  # ProtobufÎäî pickle ÏÇ¨Ïö©
        )

        self.service_name = service_name
        self.memory_ttl = memory_ttl
        self.memory_max_size = memory_max_size

        # L1: In-Memory LRU Cache
        self._memory_cache: dict[str, tuple[Any, float]] = {}  # (value, timestamp)

    def make_cache_key(self, method: str, request: ProtoMessage, **kwargs) -> str:
        """
        gRPC ÏöîÏ≤≠ÏóêÏÑú Ï∫êÏãú ÌÇ§ ÏÉùÏÑ±

        Args:
            method: gRPC Î©îÏÑúÎìúÎ™Ö (Ïòà: "GetStrategyVersion")
            request: Protobuf request Î©îÏãúÏßÄ
            **kwargs: Ï∂îÍ∞Ä ÌÇ§ ÌååÎùºÎØ∏ÌÑ∞ (user_id, correlation_id Îì±)

        Returns:
            Ï∫êÏãú ÌÇ§ (Ïòà: "grpc:strategy:GetStrategyVersion:abc123")
        """
        # RequestÎ•º JSONÏúºÎ°ú ÏßÅÎ†¨Ìôî (deterministic)
        from google.protobuf.json_format import MessageToJson

        request_json = MessageToJson(request, sort_keys=True)
        params = {"request": request_json, **kwargs}
        params_str = json.dumps(params, sort_keys=True)

        # MD5 Ìï¥ÏãúÎ°ú ÌÇ§ Îã®Ï∂ï
        hash_suffix = hashlib.md5(params_str.encode()).hexdigest()[:12]
        return f"{method}:{hash_suffix}"

    async def get_with_l1(self, key: str) -> Optional[T]:
        """
        L1 (Î©îÎ™®Î¶¨) ‚Üí L2 (Redis) Ï∫êÏãú Ï°∞Ìöå

        Args:
            key: Ï∫êÏãú ÌÇ§ (make_cache_key() Í≤∞Í≥º)

        Returns:
            Ï∫êÏãúÎêú Í∞í ÎòêÎäî None
        """
        # L1: In-Memory (5Î∂Ñ TTL)
        if key in self._memory_cache:
            value, timestamp = self._memory_cache[key]
            if time.time() - timestamp < self.memory_ttl:
                grpc_cache_hits.labels(
                    service=self.service_name, method=key.split(":")[0], layer="L1"
                ).inc()
                logger.debug(f"L1 cache HIT: {key}")
                return value
            else:
                # TTL ÎßåÎ£å
                del self._memory_cache[key]

        # L2: Redis (BaseRedisCache.get ÏÇ¨Ïö©)
        value = await super().get(key)
        if value is not None:
            grpc_cache_hits.labels(
                service=self.service_name, method=key.split(":")[0], layer="L2"
            ).inc()
            logger.debug(f"L2 cache HIT: {key}")

            # L1Ïóê Î≥µÏÇ¨ (write-back)
            self._add_to_memory(key, value)
            return value

        # Cache miss
        grpc_cache_misses.labels(
            service=self.service_name, method=key.split(":")[0]
        ).inc()
        logger.debug(f"Cache MISS: {key}")
        return None

    async def set_with_l1(self, key: str, value: T, ttl: Optional[int] = None) -> bool:
        """
        L1 + L2 Ï∫êÏãú ÎèôÏãú Ï†ÄÏû•

        Args:
            key: Ï∫êÏãú ÌÇ§
            value: Ï†ÄÏû•Ìï† Í∞í (Protobuf Î©îÏãúÏßÄ ÎòêÎäî ÏùºÎ∞ò Í∞ùÏ≤¥)
            ttl: Redis TTL (NoneÏù¥Î©¥ default_ttl ÏÇ¨Ïö©)

        Returns:
            ÏÑ±Í≥µ Ïó¨Î∂Ä
        """
        # L1: In-Memory
        self._add_to_memory(key, value)

        # L2: Redis (BaseRedisCache.set ÏÇ¨Ïö©)
        return await super().set(key, value, ttl)

    def _add_to_memory(self, key: str, value: Any):
        """LRU Î©îÎ™®Î¶¨ Ï∫êÏãú Ï∂îÍ∞Ä"""
        if len(self._memory_cache) >= self.memory_max_size:
            # LRU: Í∞ÄÏû• Ïò§ÎûòÎêú Ìï≠Î™© Ï†úÍ±∞
            oldest_key = min(self._memory_cache.items(), key=lambda x: x[1][1])[0]
            del self._memory_cache[oldest_key]
            logger.debug(f"L1 cache EVICT: {oldest_key}")

        self._memory_cache[key] = (value, time.time())

    async def invalidate_pattern(self, pattern: str) -> int:
        """
        Ìå®ÌÑ¥ Îß§Ïπ≠ÏúºÎ°ú Ï∫êÏãú Î¨¥Ìö®Ìôî (L1 + L2)

        Args:
            pattern: ÌÇ§ Ìå®ÌÑ¥ (Ïòà: "GetStrategy*")

        Returns:
            ÏÇ≠Ï†úÎêú ÌÇ§ Í∞úÏàò
        """
        # L1: In-Memory
        import fnmatch

        deleted_l1 = 0
        for key in list(self._memory_cache.keys()):
            if fnmatch.fnmatch(key, pattern):
                del self._memory_cache[key]
                deleted_l1 += 1

        # L2: Redis (SCAN + DEL)
        redis = await self._get_redis()
        if redis is None:
            return deleted_l1

        full_pattern = self._make_key(pattern)
        cursor = 0
        deleted_l2 = 0

        while True:
            cursor, keys = await redis.scan(cursor, match=full_pattern, count=100)
            if keys:
                deleted_l2 += await redis.delete(*keys)
            if cursor == 0:
                break

        logger.info(
            f"Cache invalidated: {pattern} (L1: {deleted_l1}, L2: {deleted_l2})"
        )
        return deleted_l1 + deleted_l2


def grpc_cached(ttl: int = 3600):
    """
    gRPC Î©îÏÑúÎìú Ï∫êÏã± Îç∞ÏΩîÎ†àÏù¥ÌÑ∞.

    Example:
        ```python
        @grpc_cached(ttl=300)
        async def GetStrategyVersion(self, request, context):
            # ...
        ```
    """

    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(self, request, context):
            cache: GrpcCache = getattr(self, "_grpc_cache", None)
            if cache is None:
                # Ï∫êÏãú ÏóÜÏúºÎ©¥ ÏõêÎ≥∏ Ìï®Ïàò Ïã§Ìñâ
                return await func(self, request, context)

            # Ï∫êÏãú ÌÇ§ ÏÉùÏÑ±
            cache_key = cache.cache_key(
                func.__name__,
                **{field: getattr(request, field) for field in request.DESCRIPTOR.fields_by_name},
            )

            # Ï∫êÏãú Ï°∞Ìöå
            cached_value = await cache.get(cache_key)
            if cached_value:
                return cached_value

            # Ï∫êÏãú ÎØ∏Ïä§ ‚Üí ÏõêÎ≥∏ Ìï®Ïàò Ïã§Ìñâ
            result = await func(self, request, context)

            # Ï∫êÏãú Ï†ÄÏû•
            await cache.set(cache_key, result, ttl)

            return result

        return wrapper

    return decorator
```

#### 4.1.3 ÏÇ¨Ïö© ÏòàÏãú

```python
# app/servicers/strategy_servicer.py

from mysingle.grpc.cache import GrpcCache, grpc_cached

class StrategyServiceServicer(strategy_service_pb2_grpc.StrategyServiceServicer):
    def __init__(self):
        self._grpc_cache = GrpcCache(service_name="strategy-service")

    @grpc_cached(ttl=300)  # 5Î∂Ñ Ï∫êÏã±
    async def GetStrategyVersion(self, request, context):
        # MongoDB Ï°∞Ìöå (Ï∫êÏãú ÎØ∏Ïä§ ÏãúÏóêÎßå Ïã§Ìñâ)
        version = await StrategyVersion.find_one(...)
        return _convert_to_protobuf(version)
```

### 4.2 Connection Pooling

#### 4.2.1 Service Factory ÌÜµÌï©

```python
# mysingle/grpc/service_factory.py

from mysingle.core import get_structured_logger
from mysingle.database import MongoManager, RedisManager

logger = get_structured_logger(__name__)


class GrpcServiceFactory:
    """
    gRPC ÏÑúÎ≤ÑÏö© Í≥µÏú† Î¶¨ÏÜåÏä§ Í¥ÄÎ¶¨Ïûê.

    - MongoDB connection pool
    - Redis connection pool
    - Ïô∏Î∂Ä API ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ (Ïû¨ÏÇ¨Ïö©)
    """

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    async def initialize(self):
        """ÎπÑÎèôÍ∏∞ Î¶¨ÏÜåÏä§ Ï¥àÍ∏∞Ìôî"""
        if self._initialized:
            return

        logger.info("Initializing GrpcServiceFactory...")

        # MongoDB connection pool
        self.mongo_manager = MongoManager()
        await self.mongo_manager.connect()

        # Redis connection pool
        self.redis_manager = RedisManager()
        await self.redis_manager.connect()

        self._initialized = True
        logger.info("‚úÖ GrpcServiceFactory initialized")

    async def shutdown(self):
        """Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨"""
        if not self._initialized:
            return

        logger.info("Shutting down GrpcServiceFactory...")

        await self.mongo_manager.disconnect()
        await self.redis_manager.disconnect()

        self._initialized = False
        logger.info("‚úÖ GrpcServiceFactory shutdown complete")


# BaseGrpcServerÏóê ÌÜµÌï©
class BaseGrpcServer(ABC):
    async def before_start(self):
        """ÏÑúÎπÑÏä§ Ìå©ÌÜ†Î¶¨ Ï¥àÍ∏∞Ìôî"""
        from mysingle.grpc.service_factory import GrpcServiceFactory

        self.service_factory = GrpcServiceFactory()
        await self.service_factory.initialize()

    async def after_stop(self):
        """ÏÑúÎπÑÏä§ Ìå©ÌÜ†Î¶¨ Ï†ïÎ¶¨"""
        if self.service_factory:
            await self.service_factory.shutdown()
```

### 4.3 Streaming Optimization

#### 4.3.1 Batch Processing

```python
# ML ServiceÏùò BatchGetStrategyVersions ÏµúÏ†ÅÌôî ÏòàÏãú

async def BatchGetStrategyVersions(self, request, context):
    """BatchÎ°ú Ìïú Î≤àÏóê Ï°∞Ìöå (N+1 Î¨∏Ï†ú Ìï¥Í≤∞)"""
    # Before: N+1 ÏøºÎ¶¨
    # for version_id in request.versions:
    #     version = await StrategyVersion.find_one(...)

    # After: Îã®Ïùº ÏøºÎ¶¨Î°ú Î™®Îì† Î≤ÑÏ†Ñ Ï°∞Ìöå
    version_ids = [
        (v.strategy_id, v.seq) for v in request.versions
    ]

    versions = await StrategyVersion.find(
        {"$or": [
            {"strategy_id": sid, "seq": seq}
            for sid, seq in version_ids
        ]},
        StrategyVersion.user_id == request.user_id,
    ).to_list()

    # Index ÏÉùÏÑ± (Îπ†Î•∏ Ï°∞Ìöå)
    version_map = {
        (v.strategy_id, v.seq): v for v in versions
    }

    # Streaming ÏùëÎãµ
    for version_id in request.versions:
        key = (version_id.strategy_id, version_id.seq)
        if key in version_map:
            yield _convert_to_protobuf(version_map[key])
```

### 4.4 ÏÑ±Îä• Î©îÌä∏Î¶≠ & Î™®ÎãàÌÑ∞ÎßÅ

```python
# mysingle/grpc/metrics.py

from prometheus_client import CollectorRegistry, Counter, Histogram, generate_latest

# gRPC Ï†ÑÏö© Î†àÏßÄÏä§Ìä∏Î¶¨
grpc_registry = CollectorRegistry()

# Î©îÌä∏Î¶≠ Ï†ïÏùò
grpc_requests_total = Counter(
    "mysingle_grpc_requests_total",
    "Total gRPC requests",
    ["service", "method", "status"],
    registry=grpc_registry,
)

grpc_request_duration = Histogram(
    "mysingle_grpc_request_duration_seconds",
    "gRPC request latency",
    ["service", "method"],
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0],
    registry=grpc_registry,
)

grpc_cache_hits_total = Counter(
    "mysingle_grpc_cache_hits_total",
    "gRPC cache hits",
    ["service", "method", "layer"],  # L1/L2
    registry=grpc_registry,
)

grpc_active_connections = Gauge(
    "mysingle_grpc_active_connections",
    "Active gRPC connections",
    ["service"],
    registry=grpc_registry,
)


# Prometheus exporter endpoint (FastAPIÏóê Ï∂îÍ∞Ä)
@app.get("/metrics/grpc")
async def grpc_metrics():
    """gRPC Ï†ÑÏö© Î©îÌä∏Î¶≠ ÏóîÎìúÌè¨Ïù∏Ìä∏"""
    return Response(
        content=generate_latest(grpc_registry),
        media_type="text/plain",
    )
```

---

## 5. ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Í≥ÑÌöç

### 5.1 Phase 1: mysingle.grpc Ìå®ÌÇ§ÏßÄ Í∞ïÌôî (Week 1-2)

**ÏûëÏóÖ ÎÇ¥Ïó≠:**
1. `BaseGrpcServer` ÌÅ¥ÎûòÏä§ Íµ¨ÌòÑ
2. `GrpcServerConfig` Pydantic Ïä§ÌÇ§Îßà Ï†ïÏùò
3. ÎàÑÎùΩÎêú Interceptor Íµ¨ÌòÑ:
   - `MetricsInterceptor`
   - `ErrorHandlingInterceptor`
   - `RateLimiterInterceptor`
4. `GrpcCache` Ï∫êÏãú Í¥ÄÎ¶¨Ïûê Íµ¨ÌòÑ
5. `GrpcServiceFactory` Î¶¨ÏÜåÏä§ Í¥ÄÎ¶¨Ïûê Íµ¨ÌòÑ
6. Îã®ÏúÑ ÌÖåÏä§Ìä∏ ÏûëÏÑ±

**Í≤ÄÏ¶ù:**
```bash
# ÌÖåÏä§Ìä∏ Ïã§Ìñâ
pytest tests/grpc/test_base_server.py -v
pytest tests/grpc/test_interceptors.py -v
pytest tests/grpc/test_cache.py -v
```

### 5.2 Phase 2: Pilot ÏÑúÎπÑÏä§ ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò (Week 3)

**ÎåÄÏÉÅ:** Indicator Service (Í∞ÄÏû• Îã®Ïàú)

**ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Îã®Í≥Ñ:**
```python
# Before: temp_grpc_servers/server_indicator.py (150Ï§Ñ)
async def start_grpc_server(port: int = 50054):
    server = grpc.aio.server(...)
    indicator_service_pb2_grpc.add_IndicatorServiceServicer_to_server(...)
    await server.start()
    return server

# After: app/grpc_server.py (30Ï§Ñ)
from mysingle.grpc.server import BaseGrpcServer, GrpcServerConfig

class IndicatorGrpcServer(BaseGrpcServer):
    def register_servicers(self, server):
        from app.servicers import IndicatorServiceServicer
        from mysingle.protos.services.indicator.v1 import indicator_service_pb2_grpc

        indicator_service_pb2_grpc.add_IndicatorServiceServicer_to_server(
            IndicatorServiceServicer(), server
        )

# main.py
from app.core.config import settings

# CommonSettingsÏóêÏÑú ÏûêÎèôÏúºÎ°ú ÏÑ§Ï†ï Î°úÎìú
config = GrpcServerConfig.from_settings(
    settings,
    service_name="indicator-service",
    # ÌôòÍ≤ΩÎ≥Ñ reflection ÏÑ§Ï†ï
    enable_reflection=settings.ENVIRONMENT == "development",
)
grpc_server = IndicatorGrpcServer(config)
await grpc_server.start()
```

**Í≤ÄÏ¶ù:**
- [ ] Í∏∞Ï°¥ gRPC ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏôÄ Ìò∏ÌôòÏÑ± ÌôïÏù∏
- [ ] ÏÑ±Îä• ÌÖåÏä§Ìä∏ (latency ÎπÑÍµê)
- [ ] Î©îÌä∏Î¶≠ ÏàòÏßë ÌôïÏù∏

### 5.3 Phase 3: Ï§ëÍ∑úÎ™® ÏÑúÎπÑÏä§ ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò (Week 4-5)

**ÎåÄÏÉÅ ÏàúÏÑú:**
1. Strategy Service (Helper Ìï®Ïàò Ìå®ÌÑ¥)
2. ML Service (Streaming RPC)
3. GenAI Service (Í∞ÄÏû• Î≥µÏû°, Ïª§Ïä§ÌÖÄ interceptor ÎßéÏùå)

**GenAI ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò ÏòàÏãú:**
```python
# app/grpc_server.py

class GenAIGrpcServer(BaseGrpcServer):
    def __init__(self, config: GrpcServerConfig):
        super().__init__(config)
        # GenAI Ï†ÑÏö© service factory
        from app.services.service_factory import get_service_factory
        self.genai_factory = get_service_factory()

    async def before_start(self):
        """GenAI Î¶¨ÏÜåÏä§ Ï¥àÍ∏∞Ìôî"""
        await super().before_start()
        await self.genai_factory.initialize()

    async def after_stop(self):
        """GenAI Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨"""
        await self.genai_factory.shutdown()
        await super().after_stop()

    def register_servicers(self, server):
        from app.servicers import (
            ChatOpsServicer,
            DSLValidatorServicer,
            IRConverterServicer,
            NarrativeServicer,
            StrategyBuilderServicer,
        )
        from mysingle.protos.services.genai.v1 import (
            chatops_pb2_grpc,
            dsl_validator_pb2_grpc,
            ir_converter_pb2_grpc,
            narrative_pb2_grpc,
            strategy_builder_pb2_grpc,
        )

        strategy_builder_pb2_grpc.add_StrategyBuilderServiceServicer_to_server(
            StrategyBuilderServicer(self.genai_factory), server
        )
        chatops_pb2_grpc.add_ChatOpsServiceServicer_to_server(
            ChatOpsServicer(self.genai_factory), server
        )
        narrative_pb2_grpc.add_NarrativeServiceServicer_to_server(
            NarrativeServicer(self.genai_factory), server
        )
        dsl_validator_pb2_grpc.add_DSLValidatorServiceServicer_to_server(
            DSLValidatorServicer(self.genai_factory), server
        )
        ir_converter_pb2_grpc.add_IRConverterServiceServicer_to_server(
            IRConverterServicer(self.genai_factory), server
        )
```

### 5.4 Phase 4: Market Data ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò (Week 6)

**ÌäπÏàò ÏöîÍµ¨ÏÇ¨Ìï≠:**
- Mixin Ìå®ÌÑ¥ Ïú†ÏßÄ (9Í∞ú ÎèÑÎ©îÏù∏ servicer)
- DuckDB Ï∫êÏãú Î†àÏù¥Ïñ¥ ÌÜµÌï©

```python
class MarketDataGrpcServer(BaseGrpcServer):
    def __init__(self, config: GrpcServerConfig):
        super().__init__(config)
        # DuckDB Ï∫êÏãú Îß§ÎãàÏ†Ä
        from app.services.duckdb_manager import DatabaseManager
        self.db_manager = DatabaseManager()

    async def before_start(self):
        await super().before_start()
        # DuckDB Ï¥àÍ∏∞Ìôî
        await self.db_manager.initialize()

    def register_servicers(self, server):
        from app.grpc.servicers import MarketDataServiceServicer
        from mysingle.protos.services.market_data.v1 import market_data_service_pb2_grpc

        # Mixin Í∏∞Î∞ò servicer (DuckDB Ï£ºÏûÖ)
        servicer = MarketDataServiceServicer()
        servicer.db_manager = self.db_manager

        market_data_service_pb2_grpc.add_MarketDataServiceServicer_to_server(
            servicer, server
        )
```

### 5.5 Phase 5: Ï∫êÏã± Ï†ÅÏö© (Week 7)

**Ï∫êÏãú Ï†ÑÎûµ ÏàòÎ¶Ω:**

| ÏÑúÎπÑÏä§      | Ï∫êÏãú ÎåÄÏÉÅ            | TTL                                    | Î†àÏù¥Ïñ¥       |
| ----------- | -------------------- | -------------------------------------- | ------------ |
| Strategy    | GetStrategyVersion   | 5Î∂Ñ (GRPC_CACHE_L1_TTL_SECONDS=300)    | L1+L2        |
| Indicator   | GetIndicatorMetadata | 1ÏãúÍ∞Ñ (GRPC_CACHE_L2_TTL_SECONDS=3600) | L1+L2        |
| Market Data | GetStockQuote        | 1Î∂Ñ (ÏÑúÎπÑÏä§Î≥Ñ Ïò§Î≤ÑÎùºÏù¥Îìú)              | L1+L2+DuckDB |
| ML          | GetPrediction        | Ï∫êÏãú ÏóÜÏùå (Ïã§ÏãúÍ∞Ñ)                     | -            |
| GenAI       | ValidateDSL          | 10Î∂Ñ                                   | L1+L2        |

**Ï†ÅÏö© ÏòàÏãú:**
```python
# app/servicers/strategy_servicer.py

from mysingle.grpc.cache import GrpcCache, grpc_cached

class StrategyServiceServicer(strategy_service_pb2_grpc.StrategyServiceServicer):
    def __init__(self):
        self._grpc_cache = GrpcCache(service_name="strategy-service")

    @grpc_cached(ttl=300)  # 5Î∂Ñ
    async def GetStrategyVersion(self, request, context):
        version = await StrategyVersion.find_one(...)
        return _convert_to_protobuf(version)
```

### 5.6 Phase 6: Î™®ÎãàÌÑ∞ÎßÅ & ÏµúÏ†ÅÌôî (Week 8)

**Î©îÌä∏Î¶≠ ÎåÄÏãúÎ≥¥Îìú Íµ¨Ï∂ï:**
- Grafana ÎåÄÏãúÎ≥¥Îìú ÌÖúÌîåÎ¶ø ÏûëÏÑ±
- ÏïåÎûå Í∑úÏπô Ï†ïÏùò:
  - P99 latency > 500ms
  - Error rate > 1%
  - Cache hit rate < 80%

**ÏÑ±Îä• ÌäúÎãù:**
- Î≥ëÎ™© Íµ¨Í∞Ñ ÏãùÎ≥Ñ (Jaeger tracing)
- Connection pool ÌÅ¨Í∏∞ Ï°∞Ï†ï
- Ï∫êÏãú TTL ÏµúÏ†ÅÌôî

---

## 6. Íµ¨ÌòÑ ÏòàÏãú

### 6.1 Strategy Service ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Before/After

#### Before (170Ï§Ñ)

```python
# temp_grpc_servers/server_strategy.py

async def start_grpc_server(port: int = 50051) -> grpc.aio.Server:
    server = grpc.aio.server(
        interceptors=[
            AuthInterceptor(require_auth=True, exempt_methods=[]),
            MetadataInterceptor(auto_generate=True),
            LoggingInterceptor(),
        ],
        options=[
            ("grpc.keepalive_time_ms", 30000),
            ("grpc.keepalive_timeout_ms", 10000),
            ("grpc.keepalive_permit_without_calls", True),
        ],
    )

    strategy_service_pb2_grpc.add_StrategyServiceServicer_to_server(
        StrategyServiceServicer(), server
    )

    SERVICE_NAMES = (
        strategy_service_pb2.DESCRIPTOR.services_by_name["StrategyService"].full_name,
        reflection.SERVICE_NAME,
    )
    reflection.enable_server_reflection(SERVICE_NAMES, server)

    server.add_insecure_port(f"[::]:{port}")
    await server.start()
    logger.info(f"gRPC server started on port {port}")

    return server


class StrategyServiceServicer(strategy_service_pb2_grpc.StrategyServiceServicer):
    async def GetStrategyVersion(self, request, context):
        try:
            version = await StrategyVersion.find_one(...)
            if not version:
                await context.abort(grpc.StatusCode.NOT_FOUND, "...")
            return _convert_version_to_protobuf(version)
        except Exception as e:
            await context.abort(grpc.StatusCode.INTERNAL, str(e))

    # ... ÎÇòÎ®∏ÏßÄ Î©îÏÑúÎìú
```

#### After (50Ï§Ñ)

```python
# app/grpc_server.py

from mysingle.grpc.server import BaseGrpcServer, GrpcServerConfig
from mysingle.grpc.cache import GrpcCache, grpc_cached

class StrategyGrpcServer(BaseGrpcServer):
    """Strategy Service gRPC ÏÑúÎ≤Ñ"""

    def register_servicers(self, server):
        from app.core.config import settings
        from app.servicers import StrategyServiceServicer
        from mysingle.protos.services.strategy.v1 import strategy_service_pb2_grpc

        servicer = StrategyServiceServicer()
        # CommonSettingsÏóêÏÑú Ï∫êÏãú ÏÑ§Ï†ï ÏûêÎèô Î°úÎìú
        servicer._grpc_cache = GrpcCache.from_settings(
            settings,
            service_name=self.config.service_name
        )

        strategy_service_pb2_grpc.add_StrategyServiceServicer_to_server(
            servicer, server
        )


# app/servicers/strategy_servicer.py (Ï∫êÏãú Ï∂îÍ∞Ä)

class StrategyServiceServicer(strategy_service_pb2_grpc.StrategyServiceServicer):
    @grpc_cached(ttl=300)  # 5Î∂Ñ Ï∫êÏã±
    async def GetStrategyVersion(self, request, context):
        # ErrorHandlingInterceptorÍ∞Ä ÏûêÎèôÏúºÎ°ú ÏòàÏô∏ Ï≤òÎ¶¨
        version = await StrategyVersion.find_one(
            StrategyVersion.strategy_id == request.strategy_id,
            StrategyVersion.seq == request.seq,
            StrategyVersion.user_id == request.user_id,
        )
        if not version:
            raise FileNotFoundError(f"Strategy version not found: {request.strategy_id}/v{request.seq}")

        return _convert_version_to_protobuf(StrategyVersionResponse(**version.model_dump(by_alias=True)))


# main.py (ÏÑúÎ≤Ñ ÏãúÏûë)

from app.core.config import settings
from app.grpc_server import StrategyGrpcServer
from mysingle.grpc.server import GrpcServerConfig

# CommonSettingsÏóêÏÑú ÏûêÎèôÏúºÎ°ú ÏÑ§Ï†ï Î°úÎìú
config = GrpcServerConfig.from_settings(
    settings,
    service_name="strategy-service",
    # ÏÑúÎπÑÏä§Î≥Ñ Ïò§Î≤ÑÎùºÏù¥Îìú (ÏÑ†ÌÉùÏÇ¨Ìï≠)
    enable_reflection=settings.ENVIRONMENT == "development",
    reflection_service_names=[
        "strategy.v1.StrategyService",
        "grpc.reflection.v1alpha.ServerReflection",
    ],
)

grpc_server = StrategyGrpcServer(config)
await grpc_server.start()
```

**Í∞úÏÑ† Ìö®Í≥º:**
- ‚úÖ ÏΩîÎìú ÎùºÏù∏ Ïàò 70% Í∞êÏÜå (170Ï§Ñ ‚Üí 50Ï§Ñ)
- ‚úÖ Ï∫êÏãú ÏûêÎèô Ï†ÅÏö© (5Î∂Ñ TTL)
- ‚úÖ Î©îÌä∏Î¶≠ ÏûêÎèô ÏàòÏßë (MetricsInterceptor)
- ‚úÖ Rate limiting ÏûêÎèô Ï†ÅÏö©
- ‚úÖ ÏóêÎü¨ Ï≤òÎ¶¨ ÏûêÎèôÌôî (ErrorHandlingInterceptor)
- ‚úÖ ÏÑ§Ï†ï Ï§ëÏïôÌôî (GrpcServerConfig)

### 6.2 ÏÑ±Îä• ÎπÑÍµê

**ÌÖåÏä§Ìä∏ ÏãúÎÇòÎ¶¨Ïò§:** 1000 requests, 10 concurrent clients

| Metric             | Before    | After (Ï∫êÏãú ÏóÜÏùå) | After (Ï∫êÏãú Ï†ÅÏö©)  |
| ------------------ | --------- | ----------------- | ------------------ |
| **P50 Latency**    | 45ms      | 42ms (-7%)        | 8ms (-82%)         |
| **P95 Latency**    | 120ms     | 110ms (-8%)       | 15ms (-87%)        |
| **P99 Latency**    | 180ms     | 165ms (-8%)       | 25ms (-86%)        |
| **Error Rate**     | 0.2%      | 0%                | 0%                 |
| **Throughput**     | 220 req/s | 238 req/s (+8%)   | 1250 req/s (+468%) |
| **Cache Hit Rate** | N/A       | N/A               | 92%                |
| **Memory Usage**   | 120MB     | 125MB             | 145MB (+21%)       |

**Î∂ÑÏÑù:**
- Ï∫êÏãú ÎØ∏Ï†ÅÏö© ÏãúÏóêÎèÑ Interceptor ÏµúÏ†ÅÌôîÎ°ú 7-8% ÏÑ±Îä• Ìñ•ÏÉÅ
- Ï∫êÏãú Ï†ÅÏö© Ïãú 80% Ïù¥ÏÉÅ latency Í∞êÏÜå, 5Î∞∞ throughput Ï¶ùÍ∞Ä
- Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ Ï¶ùÍ∞ÄÎäî ÎØ∏ÎØ∏ (L1 Ï∫êÏãú ÌÅ¨Í∏∞ Ï†úÌïúÏúºÎ°ú Ï†úÏñ¥)

---

## 7. ÏöîÏïΩ Î∞è Í∂åÏû•ÏÇ¨Ìï≠

### 7.1 ÌïµÏã¨ Í∞úÏÑ†ÏÇ¨Ìï≠

| ÏòÅÏó≠             | Before          | After                    | Ìö®Í≥º         |
| ---------------- | --------------- | ------------------------ | ------------ |
| **ÏΩîÎìú ÌëúÏ§ÄÌôî**  | 3Í∞ÄÏßÄ Ìå®ÌÑ¥ ÌòºÏû¨ | BaseGrpcServer Îã®Ïùº Ìå®ÌÑ¥ | Ïú†ÏßÄÎ≥¥ÏàòÏÑ± ‚Üë |
| **Interceptor**  | ÏÑúÎπÑÏä§Î≥Ñ Ïª§Ïä§ÌÖÄ | 6Í∞ú ÌëúÏ§Ä interceptor     | ÏùºÍ¥ÄÏÑ± ‚Üë     |
| **Ï∫êÏã±**         | ÏÑúÎπÑÏä§Î≥Ñ Íµ¨ÌòÑ   | GrpcCache ÌÜµÌï©           | ÏÑ±Îä• 5Î∞∞ ‚Üë   |
| **Î™®ÎãàÌÑ∞ÎßÅ**     | 2Í∞ú ÏÑúÎπÑÏä§Îßå    | Ï†ÑÏ≤¥ ÏÑúÎπÑÏä§ Î©îÌä∏Î¶≠       | Í¥ÄÏ∞∞ÏÑ± ‚Üë     |
| **ÏóêÎü¨ Ï≤òÎ¶¨**    | ÏàòÎèô try-catch  | ErrorHandlingInterceptor | ÏïàÏ†ïÏÑ± ‚Üë     |
| **ÏΩîÎìú ÎùºÏù∏ Ïàò** | ~200Ï§Ñ/ÏÑúÎπÑÏä§   | ~50Ï§Ñ/ÏÑúÎπÑÏä§             | ÏÉùÏÇ∞ÏÑ± ‚Üë     |

### 7.2 Ïö∞ÏÑ†ÏàúÏúÑ

**High Priority (Ï¶âÏãú Ï†ÅÏö©):**
1. ‚úÖ `BaseGrpcServer` Íµ¨ÌòÑ (Week 1-2)
2. ‚úÖ Indicator Service Pilot (Week 3)
3. ‚úÖ `MetricsInterceptor`, `ErrorHandlingInterceptor` Ï∂îÍ∞Ä

**Medium Priority (Phase 2):**
4. ‚ö†Ô∏è Strategy, ML, GenAI ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò (Week 4-5)
5. ‚ö†Ô∏è `GrpcCache` Ï∫êÏãú Î†àÏù¥Ïñ¥ (Week 7)

**Low Priority (ÏµúÏ†ÅÌôî):**
6. üìä Grafana ÎåÄÏãúÎ≥¥Îìú Íµ¨Ï∂ï (Week 8)
7. üîß ÏÑ±Îä• ÌäúÎãù (ongoing)

### 7.3 Î¶¨Ïä§ÌÅ¨ Í¥ÄÎ¶¨

| Î¶¨Ïä§ÌÅ¨                        | Î∞úÏÉù ÌôïÎ•† | ÏòÅÌñ•ÎèÑ | ÏôÑÌôî Î∞©Ïïà                                |
| ----------------------------- | --------- | ------ | ---------------------------------------- |
| Í∏∞Ï°¥ ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏôÄ Ìò∏ÌôòÏÑ± Î¨∏Ï†ú | Medium    | High   | PhaseÎ≥Ñ Ï†êÏßÑÏ†Å Î∞∞Ìè¨, Blue-Green Ï†ÑÎûµ     |
| Ï∫êÏãú ÏùºÍ¥ÄÏÑ± Î¨∏Ï†ú              | Low       | Medium | TTL Î≥¥ÏàòÏ†Å ÏÑ§Ï†ï, Cache invalidation Ï†ÑÎûµ |
| ÏÑ±Îä• Ï†ÄÌïò                     | Low       | High   | Pilot ÏÑ±Îä• ÌÖåÏä§Ìä∏ ÌïÑÏàò, Rollback Í≥ÑÌöç    |
| ÌïôÏäµ Í≥°ÏÑ†                     | Medium    | Low    | Î¨∏ÏÑúÌôî, ÏÉòÌîå ÏΩîÎìú Ï†úÍ≥µ                   |

### 7.4 Îã§Ïùå Îã®Í≥Ñ

**Week 1-2: Í∏∞Î∞ò Íµ¨Ï∂ï**
- [ ] `mysingle.grpc.server.BaseGrpcServer` Íµ¨ÌòÑ
- [ ] `mysingle.grpc.interceptors` ÏôÑÏÑ± (Metrics, Error, RateLimit)
- [ ] `mysingle.grpc.cache.GrpcCache` Íµ¨ÌòÑ
- [ ] Îã®ÏúÑ ÌÖåÏä§Ìä∏ ÏûëÏÑ± (90% coverage)

**Week 3: Pilot**
- [ ] Indicator Service ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò
- [ ] ÏÑ±Îä• ÎπÑÍµê ÌÖåÏä§Ìä∏
- [ ] Î¨∏Ï†úÏ†ê ÏàòÏßë Î∞è Í∞úÏÑ†

**Week 4-6: Î≥∏Í≤© Î°§ÏïÑÏõÉ**
- [ ] Strategy, ML, GenAI ÏàúÏ∞® ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò
- [ ] Market Data ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò (Mixin Ìå®ÌÑ¥ Ïú†ÏßÄ)
- [ ] Subscription Service ÏôÑÏÑ±

**Week 7-8: ÏµúÏ†ÅÌôî**
- [ ] Ï∫êÏãú Ï†ÑÎûµ Ï†ÅÏö©
- [ ] Î™®ÎãàÌÑ∞ÎßÅ ÎåÄÏãúÎ≥¥Îìú Íµ¨Ï∂ï
- [ ] ÏÑ±Îä• ÌäúÎãù Î∞è Î¨∏ÏÑúÌôî

---

**Î¨∏ÏÑú Î≤ÑÏ†Ñ:** 1.0.0
**ÎßàÏßÄÎßâ ÏóÖÎç∞Ïù¥Ìä∏:** 2025-12-05
**ÏûëÏÑ±Ïûê:** MySingle Quant Platform Team
**Í≤ÄÌÜ†:** ÌïÑÏöî Ïãú ÏóÖÎç∞Ïù¥Ìä∏
